import Foundation
import Combine
import Speech
import AVFoundation

@MainActor
class SpeechManager: ObservableObject {
    @Published var isRecording = false
    @Published var transcribedText = ""
    @Published var recognitionError: String? = nil
    
    private let speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    init() {
        self.speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "uk-UA"))
        
        if speechRecognizer == nil {
            recognitionError = "–ú–æ–≤–∞ uk-UA –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è"
            print("‚ùå SpeechRecognizer –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ")
        } else if !(speechRecognizer?.isAvailable ?? false) {
            recognitionError = "–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∑–∞—Ä–∞–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ"
            print("‚ö†Ô∏è SpeechRecognizer –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")
        } else {
            print("‚úÖ SpeechManager –≥–æ—Ç–æ–≤–∏–π (uk-UA)")
        }
    }
    
    func toggleRecording() {
        print("üîÑ Toggle: isRecording = \(isRecording)")
        if isRecording {
            stopRecording()
        } else {
            Task {
                await checkPermissionsAndStart()
            }
        }
    }
    
    private func checkPermissionsAndStart() async {
        print("üîê –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ–∑–≤–æ–ª—ñ–≤...")
        
        // –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ–∑–≤–æ–ª—É –Ω–∞ –º—ñ–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è macOS
        let micStatus = AVCaptureDevice.authorizationStatus(for: .audio)
        print("üì± –°—Ç–∞—Ç—É—Å –º—ñ–∫—Ä–æ—Ñ–æ–Ω—É: \(micStatus.rawValue)")
        
        if micStatus == .denied || micStatus == .restricted {
            await MainActor.run {
                recognitionError = "–ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω—É.\n\n–í—ñ–¥–∫—Ä–∏–π—Ç–µ: System Settings ‚Üí Privacy & Security ‚Üí Microphone\n—Ç–∞ —É–≤—ñ–º–∫–Ω—ñ—Ç—å smart_notepad"
            }
            print("‚ùå –ú—ñ–∫—Ä–æ—Ñ–æ–Ω –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ")
            return
        }
        
        if micStatus == .notDetermined {
            print("‚è≥ –ó–∞–ø–∏—Ç –¥–æ–∑–≤–æ–ª—É –Ω–∞ –º—ñ–∫—Ä–æ—Ñ–æ–Ω...")
            let granted = await AVCaptureDevice.requestAccess(for: .audio)
            print("üé§ –î–æ–∑–≤—ñ–ª –Ω–∞ –º—ñ–∫—Ä–æ—Ñ–æ–Ω: \(granted ? "–Ω–∞–¥–∞–Ω–æ" : "–≤—ñ–¥—Ö–∏–ª–µ–Ω–æ")")
            
            if !granted {
                await MainActor.run {
                    recognitionError = "–î–æ—Å—Ç—É–ø –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω—É –≤—ñ–¥—Ö–∏–ª–µ–Ω–æ.\n\n–ü–µ—Ä–µ–π–¥—ñ—Ç—å –¥–æ System Settings ‚Üí Privacy & Security ‚Üí Microphone"
                }
                return
            }
        }
        
        // –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏
        let authStatus = SFSpeechRecognizer.authorizationStatus()
        print("üó£Ô∏è –°—Ç–∞—Ç—É—Å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è: \(authStatus.rawValue)")
        
        if authStatus == .denied || authStatus == .restricted {
            await MainActor.run {
                recognitionError = "–ù–µ–º–∞—î –¥–æ–∑–≤–æ–ª—É –Ω–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏.\n\nSystem Settings ‚Üí Privacy & Security ‚Üí Speech Recognition"
            }
            print("‚ùå –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ")
            return
        }
        
        if authStatus == .notDetermined {
            print("‚è≥ –ó–∞–ø–∏—Ç –¥–æ–∑–≤–æ–ª—É –Ω–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è...")
            let granted = await withCheckedContinuation { continuation in
                SFSpeechRecognizer.requestAuthorization { status in
                    continuation.resume(returning: status == .authorized)
                }
            }
            print("üó£Ô∏è –î–æ–∑–≤—ñ–ª –Ω–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è: \(granted ? "–Ω–∞–¥–∞–Ω–æ" : "–≤—ñ–¥—Ö–∏–ª–µ–Ω–æ")")
            
            if !granted {
                await MainActor.run {
                    recognitionError = "–î–æ–∑–≤—ñ–ª –Ω–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≤—ñ–¥—Ö–∏–ª–µ–Ω–æ"
                }
                return
            }
        }
        
        // –Ø–∫—â–æ –≤—Å—ñ –¥–æ–∑–≤–æ–ª–∏ —î - –∑–∞–ø—É—Å–∫–∞—î–º–æ
        print("‚úÖ –í—Å—ñ –¥–æ–∑–≤–æ–ª–∏ –Ω–∞–¥–∞–Ω–æ, –∑–∞–ø—É—Å–∫–∞—î–º–æ –∑–∞–ø–∏—Å...")
        await MainActor.run {
            startRecording()
        }
    }
    
    private func startRecording() {
        print("‚ñ∂Ô∏è –ü–æ—á–∞—Ç–æ–∫ –∑–∞–ø–∏—Å—É...")
        
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            recognitionError = "–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ"
            print("‚ùå –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞—á –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")
            return
        }
        
        // –Ø–∫—â–æ –≤–∂–µ –π–¥–µ –∑–∞–ø–∏—Å - —Å–ø–æ—á–∞—Ç–∫—É –∑—É–ø–∏–Ω—è—î–º–æ
        if audioEngine.isRunning {
            print("‚ö†Ô∏è AudioEngine –≤–∂–µ –ø—Ä–∞—Ü—é—î, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—î–º–æ...")
            stopRecording()
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) { [weak self] in
                self?.startRecording()
            }
            return
        }
        
        transcribedText = ""
        recognitionError = nil
        
        do {
            // –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–ø–∏—Ç
            recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
            guard let recognitionRequest else {
                recognitionError = "–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∑–∞–ø–∏—Ç —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"
                print("‚ùå recognitionRequest = nil")
                return
            }
            
            recognitionRequest.shouldReportPartialResults = true
            recognitionRequest.requiresOnDeviceRecognition = false
            
            print("üéØ –°—Ç–≤–æ—Ä—é—î–º–æ recognitionTask...")
            recognitionTask = recognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
                guard let self else { return }
                
                Task { @MainActor in
                    if let result {
                        self.transcribedText = result.bestTranscription.formattedString
                        let preview = self.transcribedText.prefix(50)
                        print("üìù –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ (\(self.transcribedText.count) —Å–∏–º–≤–æ–ª—ñ–≤): \(preview)...")
                    }
                    
                    if let error {
                        print("‚ùå –ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è: \(error.localizedDescription)")
                        self.recognitionError = "–ü–æ–º–∏–ª–∫–∞: \(error.localizedDescription)"
                    }
                    
                    if error != nil || result?.isFinal == true {
                        print("‚èπÔ∏è –ó–∞–≤–µ—Ä—à—É—î–º–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (–ø–æ–º–∏–ª–∫–∞ –∞–±–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)")
                        self.stopRecording()
                    }
                }
            }
            
            // –ü—ñ–¥–∫–ª—é—á–∞—î–º–æ –∞—É–¥—ñ–æ –≤—Ö—ñ–¥
            let inputNode = audioEngine.inputNode
            let recordingFormat = inputNode.outputFormat(forBus: 0)
            
            print("üé§ –ê—É–¥—ñ–æ —Ñ–æ—Ä–º–∞—Ç: \(recordingFormat)")
            print("   Sample Rate: \(recordingFormat.sampleRate)")
            print("   Channels: \(recordingFormat.channelCount)")
            
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak recognitionRequest] buffer, _ in
                recognitionRequest?.append(buffer)
            }
            
            print("üîß –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ audioEngine...")
            audioEngine.prepare()
            
            print("‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ audioEngine...")
            try audioEngine.start()
            
            isRecording = true
            print("‚úÖ‚úÖ‚úÖ –ó–ê–ü–ò–° –ê–ö–¢–ò–í–ù–ò–ô! –ì–æ–≤–æ—Ä—ñ—Ç—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é...")
            
        } catch {
            print("‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: \(error.localizedDescription)")
            recognitionError = "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç–∏ –∑–∞–ø–∏—Å: \(error.localizedDescription)"
            stopRecording()
        }
    }
    
    func stopRecording() {
        print("‚èπÔ∏è –ó—É–ø–∏–Ω–∫–∞ –∑–∞–ø–∏—Å—É...")
        
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
            print("  üîá AudioEngine –∑—É–ø–∏–Ω–µ–Ω–æ")
        }
        
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
        
        recognitionRequest = nil
        recognitionTask = nil
        
        isRecording = false
        print("‚úÖ –ó–∞–ø–∏—Å –ó–£–ü–ò–ù–ï–ù–û")
        
        if !transcribedText.isEmpty {
            print("üìÑ –§—ñ–Ω–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç: \(transcribedText)")
        }
    }
    
    nonisolated deinit {
        print("üóëÔ∏è SpeechManager –∑–≤—ñ–ª—å–Ω–µ–Ω–æ")
    }
}
